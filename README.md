# fastapi-openai-minimal-example

An attempt at learning to build a lightweight, containerized FastAPI-based Generative AI SaaS backend.

## ğŸ“Œ Features
âœ… FastAPI-powered AI backend  
âœ… Supports JWT authentication  
âœ… Streaming & non-streaming AI responses  
âœ… Dockerized deployment  
âœ… Environment-based configurations (Dev/Prod)  

## ğŸ› ï¸ Setup & Installation

###  Set Up Environment Variables
Create a `.env.production` file:
```sh
ENVIRONMENT=production
DEBUG=False
OPENAI_API_KEY=your-openai-api-key
JWT_SECRET_KEY=your-jwt-secret
```

or

Create a `.env.development` file:
```sh
ENVIRONMENT=development
DEBUG=True
OPENAI_API_KEY=your-openai-api-key
JWT_SECRET_KEY=your-jwt-secret
```

## ğŸš€ Running Locally
### Option 1: Run Directly with Uvicorn
Install dependencies:
```sh
pip install -r requirements.txt
```

Run the FastAPI app:
```sh
uvicorn main:app --reload
```

## ğŸ³ Running with Docker
### Option 2: Run with Docker (Recommended)

Build the Docker image:
```sh
docker build -t fastapi-genai .
```

Run the container:
```sh
docker run -p 8000:8000 --env-file .env.production fastapi-genai
```

## ğŸ“¦ Running with Docker Compose
For easier deployment, use Docker Compose.

Run the service:
```sh
docker-compose up --build -d
```

Stop the service:
```sh
docker-compose down
```

## ğŸ› ï¸ API Endpoints
ğŸ“Œ API documentation is auto-generated by FastAPI.  
Visit: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ“Œ Next Steps
- ğŸ”§ Add Frontend  
- âš¡ Deploy to Cloud