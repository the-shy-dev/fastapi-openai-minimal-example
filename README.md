# fastapi-openai-minimal-example

An attempt at learning to build a lightweight, containerized FastAPI-based Generative AI SaaS backend.

## 📌 Features
✅ FastAPI-powered AI backend  
✅ Supports JWT authentication  
✅ Streaming & non-streaming AI responses  
✅ Dockerized deployment  
✅ Environment-based configurations (Dev/Prod)  

## 🛠️ Setup & Installation

###  Set Up Environment Variables
Create a `.env.production` file:
```sh
ENVIRONMENT=production
DEBUG=False
OPENAI_API_KEY=your-openai-api-key
JWT_SECRET_KEY=your-jwt-secret
```

or

Create a `.env.development` file:
```sh
ENVIRONMENT=development
DEBUG=True
OPENAI_API_KEY=your-openai-api-key
JWT_SECRET_KEY=your-jwt-secret
```

## 🚀 Running Locally
### Option 1: Run Directly with Uvicorn
Install dependencies:
```sh
pip install -r requirements.txt
```

Run the FastAPI app:
```sh
uvicorn main:app --reload
```

## 🐳 Running with Docker
### Option 2: Run with Docker (Recommended)

Build the Docker image:
```sh
docker build -t fastapi-genai .
```

Run the container:
```sh
docker run -p 8000:8000 --env-file .env.production fastapi-genai
```

## 📦 Running with Docker Compose
For easier deployment, use Docker Compose.

Run the service:
```sh
docker-compose up --build -d
```

Stop the service:
```sh
docker-compose down
```

## 🛠️ API Endpoints
📌 API documentation is auto-generated by FastAPI.  
Visit: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## 📌 Next Steps
- 🔧 Add Frontend  
- ⚡ Deploy to Cloud